NUM_WORKERS = 8
DEVICES = 2
ACCELERATOR = "gpu"
BATCH_SIZE = 4096
EMB_DIM = 100
MAX_EPOCHS = 300
NUM_EMB = 50000
NUM_ARTISTS = 11464
STOPPING_PATIENCE = 10
LR = 0.05

LOG_PATH = 'training_logs'
DATA_PATH = 'data/'
CHECKPOINT_PATH = 'checkpoints'
CHECKPOINT_FILENAME = '_{epoch:02d}-{val_loss:.4f}'
